{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "tqdm.monitor_interval = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/dataset/'\n",
    "model_save_path = 'data/wtte/model/saved_model.h5'\n",
    "test_data_path = 'data/wtte/model/test_set.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry = pd.read_csv(f'{data_dir}PdM_telemetry.csv')\n",
    "failures = pd.read_csv(f'{data_dir}PdM_failures.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**telemetry.csv** The first data source is the telemetry time-series data which consists of voltage, rotation, pressure and vibration measurements collected from 100 machines in real time averaged over every hour collected.\n",
    "\n",
    "**failures.csv** These are the records of component replacements due to failures. Each record has a date and time, machine ID and failed component type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry['datetime'] = pd.to_datetime(telemetry['datetime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "telemetry.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(telemetry.datetime.min())\n",
    "print(telemetry.datetime.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# failures\n",
    "\n",
    "failures['datetime'] = pd.to_datetime(failures['datetime'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "failures['failure'] = failures['failure'].astype('category')\n",
    "\n",
    "print('Total number of failures: {}'.format(len(failures)))\n",
    "failures.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "failures['failure'].value_counts().plot(kind='bar')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normliaze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry.iloc[:, 2:] = normalize(telemetry.iloc[:, 2:], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the Life-cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the mean, std, max, and min values for 24h periods\n",
    "def timesteps_handler(df, period='24H', fields = ['volt', 'rotate', 'pressure', 'vibration']):\n",
    "    temp = []\n",
    "    for col in fields:\n",
    "        temp.append(pd.pivot_table(df,\n",
    "                                   index='datetime',\n",
    "                                   columns='machineID',\n",
    "                                   values=col).resample(period, closed='left', label='right').mean().unstack())\n",
    "    df_mean_xh = pd.concat(temp, axis=1)\n",
    "    df_mean_xh.columns = [i + '_mean_{}'.format(period.lower()) for i in fields]\n",
    "    df_mean_xh.reset_index(inplace=True)\n",
    "\n",
    "    temp = []\n",
    "    for col in fields:\n",
    "        temp.append(pd.pivot_table(df,\n",
    "                                   index='datetime',\n",
    "                                   columns='machineID',\n",
    "                                   values=col).resample(period, closed='left', label='right').std().unstack())\n",
    "    df_sd_xh = pd.concat(temp, axis=1)\n",
    "    df_sd_xh.columns = [i + '_sd_{}'.format(period.lower()) for i in fields]\n",
    "    df_sd_xh.reset_index(inplace=True)\n",
    "    \n",
    "    temp = []\n",
    "    for col in fields:\n",
    "        temp.append(pd.pivot_table(df,\n",
    "                                   index='datetime',\n",
    "                                   columns='machineID',\n",
    "                                   values=col).resample(period, closed='left', label='right').max().unstack())\n",
    "    df_max_xh = pd.concat(temp, axis=1)\n",
    "    df_max_xh.columns = [i + '_max_{}'.format(period.lower()) for i in fields]\n",
    "    df_max_xh.reset_index(inplace=True)\n",
    "    \n",
    "    temp = []\n",
    "    for col in fields:\n",
    "        temp.append(pd.pivot_table(df,\n",
    "                                   index='datetime',\n",
    "                                   columns='machineID',\n",
    "                                   values=col).resample(period, closed='left', label='right').min().unstack())\n",
    "    df_min_xh = pd.concat(temp, axis=1)\n",
    "    df_min_xh.columns = [i + '_min_{}'.format(period.lower()) for i in fields]\n",
    "    df_min_xh.reset_index(inplace=True)\n",
    "    \n",
    "    df = pd.concat([\n",
    "        df_mean_xh,\n",
    "        df_sd_xh.iloc[:, 2:6],\n",
    "        df_max_xh.iloc[:, 2:6],\n",
    "        df_min_xh.iloc[:, 2:6]], axis=1).dropna()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24h periods\n",
    "telemetry = timesteps_handler(telemetry)\n",
    "telemetry.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Validation, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# make test and training splits\n",
    "threshold_dates = [\n",
    "        pd.to_datetime(\"2015-08-01 01:00:00\"),\n",
    "        pd.to_datetime(\"2015-11-01 01:00:00\")\n",
    "]\n",
    "\n",
    "telemetry_test = telemetry[(telemetry['datetime'] >= threshold_dates[1])]\n",
    "failures_test = failures[(failures['datetime'] >= threshold_dates[1])]\n",
    "\n",
    "print(len(telemetry_test))\n",
    "print(len(failures_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "telemetry_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "failures_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_handler(df_telemetry, df_failure):\n",
    "    sample_id = 0\n",
    "    #cols = ['instance', 'timesteps', 'volt', 'rotate', 'pressure', 'vibration']\n",
    "    cols = [\n",
    "        \"instance\",\n",
    "        \"timesteps\",\n",
    "        \"volt_mean_24h\",\n",
    "        \"rotate_mean_24h\",\n",
    "        \"pressure_mean_24h\",\n",
    "        \"vibration_mean_24h\",\n",
    "        \"volt_sd_24h\",\n",
    "        \"rotate_sd_24h\",\n",
    "        \"pressure_sd_24h\",\n",
    "        \"vibration_sd_24h\",\n",
    "        \"volt_max_24h\",\n",
    "        \"rotate_max_24h\",\n",
    "        \"pressure_max_24h\",\n",
    "        \"vibration_max_24h\",\n",
    "        \"volt_min_24h\",\n",
    "        \"rotate_min_24h\",\n",
    "        \"pressure_min_24h\",\n",
    "        \"vibration_min_24h\"\n",
    "    ]\n",
    "    dataset = pd.DataFrame(columns=cols)\n",
    "    for machine_id in df_failure.machineID.unique():\n",
    "        telemetry_sample = df_telemetry[df_telemetry['machineID'] == machine_id].sort_values(by='datetime')\n",
    "        sample_failure = df_failure[df_failure['machineID'] == machine_id].sort_values(by='datetime')\n",
    "        \n",
    "        prev_fail_datetime = pd.to_datetime(\"1900-01-01 00:00:00\")\n",
    "        for fail_datetime in sample_failure.datetime:\n",
    "            temp = telemetry_sample[\n",
    "                (telemetry_sample.datetime > prev_fail_datetime) &\n",
    "                (telemetry_sample.datetime < fail_datetime)\n",
    "            ]\n",
    "            matrix = np.concatenate(\n",
    "                    (\n",
    "                        np.array([sample_id] * len(temp))[:, None].astype(np.int16),\n",
    "                        np.arange(len(temp))[:, None].astype(np.int16),\n",
    "                        temp[cols[2:]].values\n",
    "                    ), axis=1\n",
    "                )\n",
    "            dataset = dataset.append(pd.DataFrame(matrix, columns=cols), ignore_index=True)  \n",
    "            prev_fail_datetime = fail_datetime\n",
    "            sample_id += 1\n",
    "    dataset['instance'] = dataset['instance'].astype(np.int16)\n",
    "    dataset['timesteps'] = dataset['timesteps'].astype(np.int16)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_handler(telemetry_test, failures_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(engine, time, x, max_time, is_test):\n",
    "    # y[0] will be days remaining, y[1] will be event indicator, always 1 for this data\n",
    "    out_y = np.empty((0, 2), dtype=np.float32)\n",
    "    \n",
    "    num_features = x.shape[1]\n",
    "    engine_list = np.unique(engine)\n",
    "\n",
    "    # A full history of sensor readings to date for each x\n",
    "    out_x = np.empty((0, max_time, num_features), dtype=np.float32)\n",
    "\n",
    "    for i in tqdm(engine_list):\n",
    "        # When did the engine fail? (Last day + 1 for train data, irrelevant for test.)\n",
    "        max_engine_time = int(np.max(time[engine == i])) + 1\n",
    "\n",
    "        if is_test:\n",
    "            start = random.randint(max_engine_time//4, max_engine_time)\n",
    "            print(max_engine_time)\n",
    "            print(max_engine_time//4)\n",
    "            print(start)\n",
    "            end = start + 1\n",
    "        else:\n",
    "            start = 0\n",
    "            end = max_engine_time\n",
    "\n",
    "        this_x = np.empty((0, max_time, num_features), dtype=np.float32)\n",
    "\n",
    "        for j in range(start, end):\n",
    "            engine_x = x[engine == i]\n",
    "\n",
    "            out_y = np.append(out_y, np.array((max_engine_time - j, 1), ndmin=2), axis=0)\n",
    "\n",
    "            xtemp = np.zeros((1, max_time, num_features))\n",
    "            xtemp[:, max_time-min(j, max_time-1)-1:max_time, :] = engine_x[max(0, j-max_time+1):j+1, :]\n",
    "            this_x = np.concatenate((this_x, xtemp))\n",
    "\n",
    "        out_x = np.concatenate((out_x, this_x))\n",
    "\n",
    "    return out_x, out_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = 100\n",
    "\n",
    "arr_test = test.values\n",
    "\n",
    "test_x, test_y = build_data(arr_test[:, 0], arr_test[:, 1], arr_test[:, 2:], max_time, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(test_data_path, 'wb') as f:\n",
    "    pickle.dump((test_x, test_y), f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "from tensorflow.python.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = model.predict(test_x)\n",
    "test_predict = np.resize(test_predict, (100, 2))\n",
    "test_result = np.concatenate((test_y, test_predict), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_df = pd.DataFrame(test_result, columns=['T', 'E', 'alpha', 'beta'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weibull_pdf(alpha, beta, t):\n",
    "    return (beta/alpha) * (t/alpha)**(beta-1)*np.exp(- (t/alpha)**beta)\n",
    "\n",
    "def weibull_median(alpha, beta):\n",
    "    return alpha*(-np.log(.5))**(1/beta)\n",
    "\n",
    "def weibull_mean(alpha, beta):\n",
    "    return alpha * math.gamma(1 + 1/beta)\n",
    "\n",
    "def weibull_mode(alpha, beta):\n",
    "    assert np.all(beta > 1)\n",
    "    return alpha * ((beta-1)/beta)**(1/beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_weibull_predictions(results_df):\n",
    "\n",
    "    fig, axarr = plt.subplots(3, figsize=(20,30))\n",
    "\n",
    "    t=np.arange(0,400)\n",
    "\n",
    "    palette = sns.color_palette(\"RdBu_r\", results_df.shape[0] + 1)\n",
    "    color_dict = dict(enumerate(palette))\n",
    "\n",
    "    for i, row in enumerate(results_df.iterrows()):\n",
    "        alpha=row[1]['alpha']\n",
    "        beta = row[1]['beta']\n",
    "        T = row[1]['T']\n",
    "        label = 'a={} b={}'.format(alpha, beta)\n",
    "\n",
    "        color = color_dict[i]\n",
    "        ax= axarr[0]\n",
    "        mode = weibull_mode(alpha, beta)\n",
    "        y_max = weibull_pdf(alpha, beta, mode)    \n",
    "\n",
    "        ax.plot(t, weibull_pdf(alpha, beta, t), color=color, label=label)\n",
    "        ax.scatter(T, weibull_pdf(alpha,beta, T), color=color, s=100)\n",
    "        ax.vlines(mode, ymin=0, ymax=y_max, colors=color, linestyles='--')\n",
    "\n",
    "        ax.set_title('Weibull distributions')\n",
    "    \n",
    "    ax=axarr[1]\n",
    "    \n",
    "    median_predictions = weibull_median(results_df['alpha'], results_df['beta'])\n",
    "    mean_predictions = results_df[['alpha', 'beta']].apply(lambda row: weibull_mean(row[0], row[1]), axis=1)\n",
    "    mode_predictions = weibull_mode(results_df['alpha'], results_df['beta'])\n",
    "#     x = results_df['time']\n",
    "    \n",
    "#     ax.scatter(x, results_df['T'], label='survival_time', color='black')\n",
    "\n",
    "#     ax.scatter(results_df['T'], median_predictions, label='median_prediction')\n",
    "#     ax.scatter(results_df['T'], mean_predictions, label='mean_prediction')\n",
    "    ax.scatter(results_df['T'], mode_predictions, label='m_prediction')\n",
    "    ax.set_title('MAP prediction Vs. true')\n",
    "    \n",
    "\n",
    "    ax.legend()\n",
    "    \n",
    "    ax=axarr[2]\n",
    "    sns.distplot(results_df['T'] - mode_predictions, ax=ax)\n",
    "    ax.set_title('Error')\n",
    "\n",
    "#     ax.plot(x, results_df['alpha'], label='alpha')\n",
    "#     ax.legend()\n",
    "    \n",
    "#     ax = axarr[3]\n",
    "#     ax.plot(x, results_df['beta'], label='beta')\n",
    "#     ax.legend()\n",
    "    \n",
    "#     ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "#     fig.suptitle(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_weibull_predictions(results_df=test_results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
